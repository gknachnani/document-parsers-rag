{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Parsing with Docling for RAG Systems\n",
    "\n",
    "## A Comprehensive Guide to Document Conversion and Processing\n",
    "\n",
    "This notebook demonstrates the powerful document parsing capabilities of **Docling** (v2.55.1), a Python library developed by IBM for converting various document formats into structured representations suitable for AI/ML workflows, particularly Retrieval-Augmented Generation (RAG) systems.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Basic Document Conversion** - Convert PDFs and other formats to Markdown, JSON, HTML\n",
    "2. **Multiple File Formats** - PDF, DOCX, XLSX, PPTX, HTML, Markdown, Images, Audio\n",
    "3. **Pipeline Configuration** - OCR engines, table extraction, layout analysis, VLM\n",
    "4. **LangChain Integration** - DoclingLoader and RAG pipeline with Chroma\n",
    "5. **Advanced Topics** - Enrichment, error handling\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.12 (recommended for full compatibility)\n",
    "- OpenAI API key (for RAG examples)\n",
    "- Sufficient disk space for model downloads (~2-4GB)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup\n",
    "\n",
    "### 1.1 Create Python 3.12 Virtual Environment\n",
    "\n",
    "```bash\n",
    "# Create virtual environment with Python 3.12\n",
    "python3.12 -m venv .venv\n",
    "\n",
    "# Activate the environment\n",
    "source .venv/bin/activate  # On macOS/Linux\n",
    "# .venv\\Scripts\\activate  # On Windows\n",
    "```\n",
    "\n",
    "### 1.2 Install Dependencies\n",
    "\n",
    "Run the following commands in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Docling and its optional dependencies\n",
    "# Uncomment and run these lines if you haven't installed the packages yet\n",
    "\n",
    "!uv pip install docling==2.55.1 langchain-docling langchain-openai python-dotenv\n",
    "!uv pip install docling[easyocr,vlm,asr]\n",
    "!uv pip install docling-core[chunking]\n",
    "!uv pip install chromadb transformers sentence-transformers\n",
    "!uv pip install pandas openpyxl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import docling\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(version(\"docling\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "print(\"Core imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify OpenAI API key is set (for RAG examples later)\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"OpenAI API key is configured\")\n",
    "else:\n",
    "    print(\"Warning: OpenAI API key not found. Some RAG examples will not work.\")\n",
    "    print(\"Create a .env file with: OPENAI_API_KEY=your-key-here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core modules that we'll use throughout the notebook\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
    "\n",
    "# Docling imports\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import InputFormat, ConversionStatus\n",
    "\n",
    "# Set up paths\n",
    "SAMPLE_DIR = Path(\"sample_documents\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Core imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Basic Document Conversion\n",
    "\n",
    "The `DocumentConverter` class is the main entry point for document conversion in Docling. It handles format detection, backend selection, and pipeline execution automatically.\n",
    "\n",
    "### Key Concepts:\n",
    "- **ConversionResult**: Contains the converted document, status, and any errors\n",
    "- **DoclingDocument**: The unified internal representation of any document\n",
    "- **Export Formats**: Markdown, JSON, HTML, Text, DocTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Simple PDF Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic PDF conversion example\n",
    "# Using the Docling paper from arXiv as an example\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# Initialize the converter with default settings\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert a PDF from URL\n",
    "# The Docling paper: \"Docling Technical Report\"\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "print(f\"Converting PDF from: {pdf_url}\")\n",
    "print(\"This may take a minute for the first run as models are downloaded...\")\n",
    "\n",
    "# Perform conversion\n",
    "result = converter.convert(pdf_url)\n",
    "\n",
    "# Check conversion status\n",
    "print(f\"\\nConversion Status: {result.status}\")\n",
    "print(f\"Document Name: {result.input.file.name}\")\n",
    "print(f\"Number of Pages: {len(result.pages) if result.pages else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the converted document\n",
    "doc = result.document\n",
    "\n",
    "# Display document structure information\n",
    "print(f\"Document Type: {type(doc).__name__}\")\n",
    "print(f\"Number of Tables: {len(doc.tables) if hasattr(doc, 'tables') else 0}\")\n",
    "print(f\"Number of Pictures: {len(doc.pictures) if hasattr(doc, 'pictures') else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display Tables\n",
    "# print(\"=\" * 50)\n",
    "# print(\"TABLES\")\n",
    "# print(\"=\" * 50)\n",
    "\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    for i, table in enumerate(doc.tables):\n",
    "        print(f\"\\n--- Table {i+1} ---\")\n",
    "        # Export table to markdown format\n",
    "        print(table.export_to_markdown())\n",
    "else:\n",
    "    print(\"No tables found\")\n",
    "\n",
    "# Display Pictures\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PICTURES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if hasattr(doc, 'pictures') and doc.pictures:\n",
    "    for i, picture in enumerate(doc.pictures):\n",
    "        print(f\"\\n--- Picture {i+1} ---\")\n",
    "        # Get caption or text associated with the picture\n",
    "        if hasattr(picture, 'caption') and picture.caption:\n",
    "            print(f\"Caption: {picture.caption}\")\n",
    "        if hasattr(picture, 'text') and picture.text:\n",
    "            print(f\"Text: {picture.text}\")\n",
    "        # Show any available metadata\n",
    "        if hasattr(picture, 'prov'):\n",
    "            print(f\"Provenance: {picture.prov}\")\n",
    "else:\n",
    "    print(\"No pictures found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Export Formats\n",
    "\n",
    "Docling supports multiple export formats:\n",
    "\n",
    "| Method | Output | Use Case |\n",
    "|--------|--------|----------|\n",
    "| `export_to_markdown()` | Markdown text | LLM input, readable output |\n",
    "| `export_to_dict()` | Python dict | Programmatic access |\n",
    "| `save_as_json()` | JSON file | Persistence, API responses |\n",
    "| `save_as_html()` | HTML file | Web display |\n",
    "| `export_to_text()` | Plain text | Simple text extraction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Markdown\n",
    "markdown_content = doc.export_to_markdown()\n",
    "\n",
    "# Display first 2000 characters\n",
    "print(\"=\" * 80)\n",
    "print(\"MARKDOWN OUTPUT (first 2000 chars)\")\n",
    "print(\"=\" * 80)\n",
    "print(markdown_content[:2000])\n",
    "print(\"\\n... [truncated] ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON (save to file)\n",
    "json_output_path = OUTPUT_DIR / \"docling_paper.json\"\n",
    "doc.save_as_json(json_output_path)\n",
    "print(f\"JSON saved to: {json_output_path}\")\n",
    "\n",
    "# Export to HTML\n",
    "html_output_path = OUTPUT_DIR / \"docling_paper.html\"\n",
    "doc.save_as_html(html_output_path)\n",
    "print(f\"HTML saved to: {html_output_path}\")\n",
    "\n",
    "# Export to Markdown file\n",
    "md_output_path = OUTPUT_DIR / \"docling_paper.md\"\n",
    "with open(md_output_path, \"w\") as f:\n",
    "    f.write(markdown_content)\n",
    "print(f\"Markdown saved to: {md_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to dictionary for programmatic access\n",
    "doc_dict = doc.export_to_dict()\n",
    "\n",
    "# Explore the structure\n",
    "print(\"Document Dictionary Keys:\")\n",
    "for key in doc_dict.keys():\n",
    "    print(f\"  - {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ConversionResult Structure\n",
    "\n",
    "The `ConversionResult` object contains valuable metadata about the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the ConversionResult structure\n",
    "print(\"ConversionResult Attributes:\")\n",
    "print(f\"  status: {result.status}\")\n",
    "print(f\"  input.file: {result.input.file}\")\n",
    "print(f\"  input.format: {result.input.format}\")\n",
    "print(f\"  input.document_hash: {result.input.document_hash[:16]}...\")\n",
    "\n",
    "# Check for errors\n",
    "if result.errors:\n",
    "    print(f\"\\nErrors ({len(result.errors)}):\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  - {error.component_type}: {error.error_message}\")\n",
    "else:\n",
    "    print(\"\\nNo errors during conversion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Supported File Formats\n",
    "\n",
    "Docling supports a wide variety of input formats, each handled by specialized backends:\n",
    "\n",
    "| Format | Extensions | Backend | Pipeline |\n",
    "|--------|-----------|---------|----------|\n",
    "| PDF | `.pdf` | DoclingParseV4Backend | StandardPdfPipeline |\n",
    "| Word | `.docx` | MsWordDocumentBackend | SimplePipeline |\n",
    "| Excel | `.xlsx` | MsExcelDocumentBackend | SimplePipeline |\n",
    "| PowerPoint | `.pptx` | MsPowerpointDocumentBackend | SimplePipeline |\n",
    "| HTML | `.html`, `.htm` | HTMLDocumentBackend | SimplePipeline |\n",
    "| Markdown | `.md` | MarkdownDocumentBackend | SimplePipeline |\n",
    "| Images | `.png`, `.jpg`, `.tiff` | ImageDocumentBackend | StandardPdfPipeline |\n",
    "| Audio | `.wav`, `.mp3` | AudioBackend | AsrPipeline |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PDF Documents\n",
    "\n",
    "PDF is the most feature-rich format with support for:\n",
    "- Layout analysis (headers, paragraphs, lists)\n",
    "- Table structure extraction\n",
    "- OCR for scanned pages\n",
    "- Image/figure extraction\n",
    "- Reading order determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF with detailed options\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Configure PDF pipeline with specific options\n",
    "pdf_options = PdfPipelineOptions(\n",
    "    do_ocr=False,              # Disable OCR for native PDFs (faster)\n",
    "    do_table_structure=True,   # Enable table structure extraction\n",
    "    generate_page_images=True, # Generate page images for HTML export\n",
    ")\n",
    "\n",
    "# Create converter with custom options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert the PDF\n",
    "result = converter.convert(pdf_url)\n",
    "print(f\"Conversion status: {result.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access tables from the converted document\n",
    "doc = result.document\n",
    "\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"Found {len(doc.tables)} tables in the document\\n\")\n",
    "    \n",
    "    # Display first table\n",
    "    for i, table in enumerate(doc.tables[:2]):  # Show first 2 tables\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Try to export to DataFrame if pandas is available\n",
    "        try:\n",
    "            df = table.export_to_dataframe()\n",
    "            print(df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"Table markdown: {table.export_to_markdown()[:500]}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No tables found in the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Microsoft Office Documents\n",
    "\n",
    "Docling supports Office Open XML formats (DOCX, XLSX, PPTX) with rich formatting preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HTML document (from our sample files)\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert the sample HTML file\n",
    "html_path = SAMPLE_DIR / \"sample.html\"\n",
    "\n",
    "if html_path.exists():\n",
    "    result = converter.convert(str(html_path))\n",
    "    print(f\"HTML Conversion Status: {result.status}\")\n",
    "    \n",
    "    # Display converted content\n",
    "    html_markdown = result.document.export_to_markdown()\n",
    "    print(\"\\nConverted HTML to Markdown:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(html_markdown[:1500])\n",
    "else:\n",
    "    print(f\"Sample HTML file not found at {html_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Markdown document\n",
    "md_path = SAMPLE_DIR / \"sample.md\"\n",
    "\n",
    "if md_path.exists():\n",
    "    result = converter.convert(str(md_path))\n",
    "    print(f\"Markdown Conversion Status: {result.status}\")\n",
    "    \n",
    "    # Markdown to Markdown (demonstrates parsing and re-export)\n",
    "    output_md = result.document.export_to_markdown()\n",
    "    print(\"\\nParsed and re-exported Markdown:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(output_md[:1500])\n",
    "else:\n",
    "    print(f\"Sample Markdown file not found at {md_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Converting a DOCX file (if you have one)\n",
    "# This demonstrates the pattern for Word documents\n",
    "\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, WordFormatOption\n",
    "\n",
    "# Configure for Word documents\n",
    "converter = DocumentConverter(\n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.PPTX, InputFormat.XLSX],  # Only allow DOCX\n",
    ")\n",
    "\n",
    "# Excel conversion pattern\n",
    "print(\"Excel (DOCX) Conversion:\")\n",
    "print(\"-\" * 40)\n",
    "result = converter.convert(\"sample_documents/sample.docx\")\n",
    "docx = result.document\n",
    "docx_markdown = docx.export_to_markdown()\n",
    "\n",
    "print(\"Word document conversion pattern demonstrated.\")\n",
    "print(\"To convert a Word document, use: converter.convert('your_document.docx')\")\n",
    "print(docx_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "  \n",
    "# Initialize converter with office document support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.XLSX, InputFormat.PPTX]  \n",
    ")  \n",
    "  \n",
    "# Convert any office document  \n",
    "result = converter.convert(\"sample_documents/sample.xlsx\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "  \n",
    "# Initialize converter with office document support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.DOCX, InputFormat.XLSX, InputFormat.PPTX]  \n",
    ")  \n",
    "print(\"\\nPowerPoint (PPTX) Conversion:\")\n",
    "print(\"-\" * 40)\n",
    "# Convert any office document \n",
    "# Each slide becomes a section in the document\n",
    "result = converter.convert(\"sample_documents/dl.pptx\")  \n",
    "# result = converter.convert(\"sample_documents/sample1.pptx\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Image Files with OCR\n",
    "\n",
    "Images are processed through the same pipeline as PDFs, with OCR enabled to extract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image conversion with OCR\n",
    "from docling.document_converter import DocumentConverter, ImageFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Configure OCR for images\n",
    "image_pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,  # Enable OCR for text extraction from images\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: ImageFormatOption(\n",
    "            pipeline_options=image_pipeline_options\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conversion pattern:\n",
    "result = converter.convert(\"sample_documents/scan.pdf\")\n",
    "text = result.document.export_to_markdown()\n",
    "\n",
    "print(\"Image OCR conversion pattern:\")\n",
    "print(\"-\" * 40)\n",
    "print(text)\n",
    "print(\"Supported formats: PNG, JPEG, TIFF, BMP, WEBP\")\n",
    "print(\"Multi-page TIFF files are automatically handled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Audio Files (ASR Pipeline)\n",
    "\n",
    "Docling can transcribe audio files using Automatic Speech Recognition (ASR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in a GPU\n",
    "\n",
    "https://colab.research.google.com/drive/1EemOQ8V5BeGz1v7W2xjD6YUC3eZdJLOU?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter  \n",
    "from docling.datamodel.base_models import InputFormat  \n",
    "from docling.datamodel import asr_model_specs  \n",
    "  \n",
    "# Initialize converter with ASR support  \n",
    "converter = DocumentConverter(  \n",
    "    allowed_formats=[InputFormat.AUDIO],  \n",
    "    format_options={  \n",
    "        InputFormat.AUDIO: AudioFormatOption(  \n",
    "            pipeline_cls=AsrPipeline,  \n",
    "            pipeline_options=AsrPipelineOptions(  \n",
    "                asr_options=asr_model_specs.WHISPER_TINY  \n",
    "            )  \n",
    "        )  \n",
    "    }  \n",
    ")  \n",
    "  \n",
    "# Convert audio file  \n",
    "result = converter.convert(\"sample_documents/sample.mp3\")  \n",
    "print(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio transcription example (requires 'asr' extra)\n",
    "from docling.document_converter import DocumentConverter, AudioFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.asr_pipeline import AsrPipeline\n",
    "from docling.datamodel.pipeline_options import AsrPipelineOptions\n",
    "from docling.datamodel import asr_model_specs\n",
    "\n",
    "print(\"Audio Transcription (ASR) Pattern:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Configure ASR pipeline\n",
    "asr_options = AsrPipelineOptions(\n",
    "    asr_options=asr_model_specs.WHISPER_TINY,  # or WHISPER_BASE, WHISPER_SMALL\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.AUDIO: AudioFormatOption(\n",
    "            pipeline_cls=AsrPipeline,\n",
    "            pipeline_options=asr_options,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "result = converter.convert(\"sample_documents/sample.mp3\")  # or .wav\n",
    "transcript = result.document.export_to_markdown()\n",
    "print(transcript)\n",
    "print(\"\\nSupported formats: WAV, MP3\")\n",
    "print(\"Requires: pip install 'docling[asr]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM Pipeline Configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "vlm_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "# Convert with VLM\n",
    "pdf_url=\"https://arxiv.org/pdf/2408.09869\"\n",
    "result = vlm_converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Pipeline Options & Configuration\n",
    "\n",
    "Docling provides extensive configuration options for customizing the document processing pipeline.\n",
    "\n",
    "### 4.1 OCR Configuration\n",
    "\n",
    "Multiple OCR engines are available, each with different strengths:\n",
    "\n",
    "| Engine | Best For | Installation |\n",
    "|--------|----------|-------------|\n",
    "| RapidOCR | General use (default) | Included |\n",
    "| EasyOCR | Multi-language | `pip install 'docling[easyocr]'` |\n",
    "| Tesseract | Production | System install + `pip install 'docling[tesserocr]'` |\n",
    "| OcrMac | macOS native | `pip install 'docling[ocrmac]'` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Configuration Examples\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    EasyOcrOptions,\n",
    "    RapidOcrOptions,\n",
    "    TesseractOcrOptions,\n",
    ")\n",
    "\n",
    "# Option 1: RapidOCR (default, fast)\n",
    "rapid_ocr_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=RapidOcrOptions(),\n",
    ")\n",
    "\n",
    "# Option 2: EasyOCR (multi-language support)\n",
    "easy_ocr_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=EasyOcrOptions(\n",
    "        lang=[\"en\", \"fr\", \"de\"],  # English, French, German\n",
    "        use_gpu=True,  # Use GPU if available\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Option 3: Tesseract (production-ready)\n",
    "tesseract_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    ocr_options=TesseractOcrOptions(\n",
    "        lang=[\"eng\", \"fra\"],  # Tesseract language codes\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"OCR configurations created successfully!\")\n",
    "print(\"\\nAvailable OCR options:\")\n",
    "print(\"  - RapidOcrOptions: Fast, general-purpose\")\n",
    "print(\"  - EasyOcrOptions: Multi-language, GPU support\")\n",
    "print(\"  - TesseractOcrOptions: Production, requires system Tesseract\")\n",
    "print(\"  - OcrMacOptions: macOS Vision framework (macOS only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using EasyOCR with custom language support\n",
    "# This example shows how to set up OCR for scanned documents\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions\n",
    "from docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice\n",
    "\n",
    "# Configure EasyOCR with accelerator options\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    do_table_structure=True,\n",
    "    ocr_options=EasyOcrOptions(\n",
    "        lang=[\"en\"],\n",
    "    ),\n",
    "    accelerator_options=AcceleratorOptions(\n",
    "        device=AcceleratorDevice.AUTO,  # AUTO, CPU, CUDA, or MPS\n",
    "        num_threads=4,\n",
    "    ),\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conversion pattern:\n",
    "result = converter.convert(\"sample_documents/scan.pdf\")\n",
    "text = result.document.export_to_markdown()\n",
    "print(\"Converter configured with EasyOCR and accelerator options.\")\n",
    "print(f\"Accelerator device: {AcceleratorDevice.AUTO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Table Structure Options\n",
    "\n",
    "Configure table extraction with TableFormer model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table structure configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    TableStructureOptions,\n",
    "    TableFormerMode,\n",
    ")\n",
    "\n",
    "# Configure table extraction\n",
    "table_options = TableStructureOptions(\n",
    "    do_cell_matching=True,  # Match cells with text content\n",
    "    mode=TableFormerMode.ACCURATE,  # ACCURATE or FAST\n",
    ")\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,\n",
    "    table_structure_options=table_options,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Conversion pattern:\n",
    "pdf_url =\"https://arxiv.org/pdf/2408.09869v1\"\n",
    "result = converter.convert(pdf_url)\n",
    "text = result.document.export_to_markdown()\n",
    "print(\"Table extraction configured:\")\n",
    "print(f\"  - Cell matching: {table_options.do_cell_matching}\")\n",
    "print(f\"  - Mode: {table_options.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 VLM Pipeline (Vision-Language Models)\n",
    "\n",
    "For complex documents, Vision-Language Models provide end-to-end understanding.\n",
    "\n",
    "**Available VLM Models:**\n",
    "- `GRANITEDOCLING_TRANSFORMERS` - IBM GraniteDocling with Transformers\n",
    "- `GRANITEDOCLING_MLX` - GraniteDocling optimized for Apple Silicon\n",
    "- `SMOLDOCLING_TRANSFORMERS` - Smaller, faster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM Pipeline Configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"VLM Pipeline Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Option 1: GraniteDocling with Transformers (cross-platform)\n",
    "print(\"\\n1. GraniteDocling with Transformers (GPU/CPU):\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\"\"pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\"\"\")\n",
    "\n",
    "# Option 2: GraniteDocling MLX (Apple Silicon optimized)\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "print(\"\"\"pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 2: GraniteDocling MLX (Apple Silicon optimized)\n",
    "\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "print(\"\\n2. GraniteDocling MLX (Apple Silicon M1/M2/M3/M4):\")\n",
    "print(\"-\" * 40)\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_MLX,\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "# Convert with VLM\n",
    "pdf_url=\"https://arxiv.org/pdf/2408.09869\"\n",
    "result = converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VLM Pipeline - Live Example (requires significant GPU/memory)\n",
    "# Uncomment to run if you have sufficient resources\n",
    "\n",
    "\"\"\"from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "\n",
    "# Configure VLM pipeline\n",
    "pipeline_options = VlmPipelineOptions(\n",
    "    vlm_options=vlm_model_specs.GRANITEDOCLING_TRANSFORMERS,\n",
    ")\n",
    "\n",
    "vlm_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert with VLM\n",
    "result = vlm_converter.convert(pdf_url)\n",
    "vlm_markdown = result.document.export_to_markdown()\n",
    "print(vlm_markdown[:2000])\n",
    "\"\"\"\n",
    "\n",
    "print(\"VLM example is commented out to avoid resource issues.\")\n",
    "print(\"Uncomment and run if you have GPU/sufficient memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. LangChain Integration\n",
    "\n",
    "Docling integrates seamlessly with LangChain through the `langchain-docling` package.\n",
    "\n",
    "### 6.1 DoclingLoader\n",
    "\n",
    "The `DoclingLoader` provides a LangChain-compatible document loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoclingLoader Basic Usage\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "# Create loader with DOC_CHUNKS export (recommended for RAG)\n",
    "loader = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    export_type=ExportType.DOC_CHUNKS,  # Returns chunked documents\n",
    ")\n",
    "\n",
    "print(\"Loading documents with DoclingLoader...\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"\\nLoaded {len(docs)} document chunks\")\n",
    "print(\"\\nFirst document chunk:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Content: {docs[0].page_content[:500]}...\")\n",
    "print(f\"\\nMetadata: {docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoclingLoader with MARKDOWN export\n",
    "loader_md = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    export_type=ExportType.MARKDOWN,  # Returns full document as Markdown\n",
    ")\n",
    "\n",
    "docs_md = loader_md.load()\n",
    "\n",
    "print(f\"Loaded {len(docs_md)} document(s) as Markdown\")\n",
    "print(f\"\\nDocument length: {len(docs_md[0].page_content)} characters\")\n",
    "print(\"\\nFirst 500 characters:\")\n",
    "print(docs_md[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoclingLoader with custom converter\n",
    "from langchain_docling import DoclingLoader\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Create custom converter with specific options\n",
    "custom_pipeline = PdfPipelineOptions(\n",
    "    do_ocr=False,\n",
    "    do_table_structure=True,\n",
    ")\n",
    "\n",
    "custom_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=custom_pipeline)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use custom converter with DoclingLoader\n",
    "loader_custom = DoclingLoader(\n",
    "    file_path=pdf_url,\n",
    "    converter=custom_converter,  # Pass custom converter\n",
    "    export_type=ExportType.DOC_CHUNKS,\n",
    ")\n",
    "\n",
    "docs_custom = loader_custom.load()\n",
    "print(f\"Loaded {len(docs_custom)} chunks with custom converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 RAG Pipeline with LangChain\n",
    "\n",
    "Build a complete RAG pipeline using Docling, LangChain, and Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete RAG Pipeline Setup\n",
    "import os\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "# Check for OpenAI API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Warning: OPENAI_API_KEY not set. RAG example will not work.\")\n",
    "    print(\"Set your API key: os.environ['OPENAI_API_KEY'] = 'your-key'\")\n",
    "else:\n",
    "    print(\"OpenAI API key found. Proceeding with RAG setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and chunk documents\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 1: Loading documents...\")\n",
    "    \n",
    "    loader = DoclingLoader(\n",
    "        file_path=pdf_url,\n",
    "        export_type=ExportType.DOC_CHUNKS,\n",
    "    )\n",
    "    \n",
    "    documents = loader.load()\n",
    "    print(f\"Loaded {len(documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create embeddings and vector store\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 2: Creating embeddings and vector store...\")\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    # Filter complex metadata from documents\n",
    "    filtered_documents = filter_complex_metadata(documents)\n",
    "    \n",
    "    # Create Chroma vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=filtered_documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\",  # Persist to disk\n",
    "        collection_name=\"docling_demo\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Vector store created with {len(documents)} documents\")\n",
    "    print(f\"Persisted to: ./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Step 3: Create RAG chain\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 3: Creating RAG chain...\")\n",
    "    \n",
    "    # Initialize LLM\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "          # Create prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "          (\"system\", \"Answer the question based only on the following context:\\n\\n{context}\"),\n",
    "          (\"human\", \"{input}\")\n",
    "      ])\n",
    "    \n",
    "    # Create retriever\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5},  # Return top 5 relevant chunks\n",
    "    )\n",
    "    \n",
    "    # Create QA chain\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    \n",
    "    print(\"RAG chain created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke({\"input\": \"What is this document about?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Query the RAG system\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"Step 4: Querying the RAG system...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example questions about Docling\n",
    "    questions = [\n",
    "        \"What is Docling and what are its main features?\",\n",
    "        \"What file formats does Docling support?\",\n",
    "        \"How does Docling handle table extraction?\",\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nQ: {question}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        response = qa_chain.invoke({\"input\": question})\n",
    "        \n",
    "        #print(f\"A: {response['input']}\")\n",
    "        #print(f\"\\n(Based on {len(response['source_documents'])} source documents)\")\n",
    "        print(\"=\" * 60)\n",
    "        print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Export & Serialization\n",
    "\n",
    "### 7.1 Export Methods\n",
    "\n",
    "Docling provides multiple export methods for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive export examples\n",
    "from docling.document_converter import DocumentConverter\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(pdf_url)\n",
    "doc = result.document\n",
    "\n",
    "# 1. Export to Markdown\n",
    "markdown = doc.export_to_markdown()\n",
    "print(f\"Markdown export: {len(markdown)} characters\")\n",
    "\n",
    "# 2. Export to Text (plain text, no formatting)\n",
    "text = doc.export_to_markdown(strict_text=True)\n",
    "print(f\"Text export: {len(text)} characters\")\n",
    "\n",
    "# 3. Export to Dictionary\n",
    "doc_dict = doc.export_to_dict()\n",
    "print(f\"Dict export: {len(doc_dict.keys())} top-level keys\")\n",
    "\n",
    "# 4. Save as JSON\n",
    "json_path = OUTPUT_DIR / \"export_demo.json\"\n",
    "doc.save_as_json(json_path)\n",
    "print(f\"JSON saved: {json_path}\")\n",
    "\n",
    "# 5. Save as HTML\n",
    "html_path = OUTPUT_DIR / \"export_demo.html\"\n",
    "doc.save_as_html(html_path)\n",
    "print(f\"HTML saved: {html_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Table Export\n",
    "\n",
    "Export tables to pandas DataFrames or CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table export to DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Access tables from the document\n",
    "if hasattr(doc, 'tables') and doc.tables:\n",
    "    print(f\"Found {len(doc.tables)} tables\\n\")\n",
    "    \n",
    "    for i, table in enumerate(doc.tables[:3]):  # First 3 tables\n",
    "        print(f\"Table {i+1}:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Export to DataFrame\n",
    "            df = table.export_to_dataframe()\n",
    "            print(df.head())\n",
    "            \n",
    "            # Save to CSV\n",
    "            csv_path = OUTPUT_DIR / f\"table_{i+1}.csv\"\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Saved to: {csv_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error exporting table: {e}\")\n",
    "        \n",
    "        print()\n",
    "else:\n",
    "    print(\"No tables found in the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Advanced Topics\n",
    "\n",
    "### 8.1 Batch Processing\n",
    "\n",
    "Process multiple documents efficiently with `convert_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing example\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "from pathlib import Path\n",
    "\n",
    "# Define sources (can be paths, URLs, or streams)\n",
    "sources = [\n",
    "    str(SAMPLE_DIR / \"sample.html\"),\n",
    "    str(SAMPLE_DIR / \"sample.md\"),\n",
    "]\n",
    "\n",
    "# Filter to existing files only\n",
    "existing_sources = [s for s in sources if Path(s).exists()]\n",
    "\n",
    "if existing_sources:\n",
    "    converter = DocumentConverter()\n",
    "    \n",
    "    # Batch convert with error handling\n",
    "    results = {\n",
    "        \"success\": [],\n",
    "        \"partial\": [],\n",
    "        \"failed\": [],\n",
    "    }\n",
    "    \n",
    "    print(f\"Processing {len(existing_sources)} documents...\")\n",
    "    \n",
    "    for result in converter.convert_all(existing_sources, raises_on_error=False):\n",
    "        if result.status == ConversionStatus.SUCCESS:\n",
    "            results[\"success\"].append(result)\n",
    "            print(f\"  SUCCESS: {result.input.file.name}\")\n",
    "        elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n",
    "            results[\"partial\"].append(result)\n",
    "            print(f\"  PARTIAL: {result.input.file.name}\")\n",
    "        else:\n",
    "            results[\"failed\"].append(result)\n",
    "            print(f\"  FAILED: {result.input.file.name}\")\n",
    "    \n",
    "    print(f\"\\nSummary: {len(results['success'])} success, \"\n",
    "          f\"{len(results['partial'])} partial, \"\n",
    "          f\"{len(results['failed'])} failed\")\n",
    "else:\n",
    "    print(\"No sample files found for batch processing demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Document Enrichment\n",
    "\n",
    "Enable enrichment features like picture classification and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document enrichment configuration\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "# Enable enrichment features\n",
    "enrichment_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,\n",
    "    do_picture_classification=True,   # Classify pictures (chart, diagram, etc.)\n",
    "    do_picture_description=False,     # Disable VLM description (resource intensive)\n",
    "    generate_picture_images=True,     # Save picture images\n",
    ")\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=enrichment_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Enrichment features configured:\")\n",
    "print(f\"  - Picture classification: {enrichment_options.do_picture_classification}\")\n",
    "print(f\"  - Picture description: {enrichment_options.do_picture_description}\")\n",
    "print(f\"  - Generate picture images: {enrichment_options.generate_picture_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Error Handling\n",
    "\n",
    "Handle conversion errors gracefully with status checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling patterns\n",
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def safe_convert(source):\n",
    "    \"\"\"Safely convert a document with proper error handling.\"\"\"\n",
    "    try:\n",
    "        result = converter.convert(source, raises_on_error=False)\n",
    "        \n",
    "        if result.status == ConversionStatus.SUCCESS:\n",
    "            print(f\"Conversion successful: {result.input.file.name}\")\n",
    "            return result.document\n",
    "        \n",
    "        elif result.status == ConversionStatus.PARTIAL_SUCCESS:\n",
    "            print(f\"Partial success: {result.input.file.name}\")\n",
    "            print(f\"  Errors: {len(result.errors)}\")\n",
    "            for error in result.errors:\n",
    "                print(f\"    - {error.component_type}: {error.error_message}\")\n",
    "            return result.document  # Still usable\n",
    "        \n",
    "        else:\n",
    "            print(f\"Conversion failed: {result.input.file.name}\")\n",
    "            for error in result.errors:\n",
    "                print(f\"  - {error.component_type}: {error.error_message}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "doc = safe_convert(pdf_url)\n",
    "if doc:\n",
    "    print(f\"\\nDocument ready with {len(doc.export_to_markdown())} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Installation & Setup** - Installing Docling 2.55.1 with all dependencies\n",
    "2. **Basic Conversion** - Converting documents to Markdown, JSON, HTML\n",
    "3. **File Formats** - PDF, Office (DOCX, XLSX, PPTX), HTML, Markdown, Images, Audio\n",
    "4. **Pipeline Options** - OCR engines, table extraction, layout analysis, VLM\n",
    "5. **Chunking** - HybridChunker and HierarchicalChunker for RAG\n",
    "6. **LangChain Integration** - DoclingLoader and RAG pipeline\n",
    "7. **Export Methods** - Multiple output formats and table export\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Docling** provides unified document parsing across multiple formats\n",
    "- **DocumentConverter** is the main entry point for all conversions\n",
    "- **Pipeline options** allow fine-tuned control over processing\n",
    "- **Native chunking** is optimized for RAG applications\n",
    "- **LangChain integration** enables seamless RAG pipeline creation\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Docling Documentation](https://docling-project.github.io/docling/)\n",
    "- [Docling GitHub](https://github.com/docling-project/docling)\n",
    "- [LangChain Docling Integration](https://docs.langchain.com/oss/python/integrations/document_loaders/docling)\n",
    "- [Docling Examples](https://docling-project.github.io/docling/examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "import shutil\n",
    "\n",
    "# Uncomment to clean up generated files\n",
    "# if OUTPUT_DIR.exists():\n",
    "#     shutil.rmtree(OUTPUT_DIR)\n",
    "# if Path(\"./chroma_db\").exists():\n",
    "#     shutil.rmtree(\"./chroma_db\")\n",
    "# if Path(\"./chroma_rag_demo\").exists():\n",
    "#     shutil.rmtree(\"./chroma_rag_demo\")\n",
    "\n",
    "print(\"Notebook completed successfully!\")\n",
    "print(f\"Output files saved to: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (optional)\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Uncomment to clean up generated files\n",
    "# if OUTPUT_DIR.exists():\n",
    "#     shutil.rmtree(OUTPUT_DIR)\n",
    "if Path(\"./chroma_db\").exists():\n",
    "    shutil.rmtree(\"./chroma_db\")\n",
    "# if Path(\"./chroma_rag_demo\").exists():\n",
    "#     shutil.rmtree(\"./chroma_rag_demo\")\n",
    "\n",
    "print(\"Notebook completed successfully!\")\n",
    "?print(f\"Output files saved to: {OUTPUT_DIR.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-parsers-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
